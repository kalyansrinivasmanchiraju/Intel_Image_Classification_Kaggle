{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intel_Image_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G96FEkphY4ig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a3907e87-bc95-4bad-9afa-3cc6af130c3d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, MaxPool2D, AvgPool2D, Add, Dense \n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "from tensorflow.keras.layers import Input,Dropout, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model,Sequential\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "\n",
        "import warnings\n",
        "warnings.warn(\"ignore\")\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: ignore\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caT4NPF0OCqS",
        "colab_type": "text"
      },
      "source": [
        "**Import data from Drive into Notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92AY8k_Xg4Ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V9ZqYfMZNld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7e25f562-d340-4c9d-bc68-bed6a4ad4c6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4s_N_TmOP8D",
        "colab_type": "text"
      },
      "source": [
        "**Converting Image to Array**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnHfHxQYObaH",
        "colab_type": "text"
      },
      "source": [
        "1. Defining a function Convert to perform our required action\n",
        "2. Using load_img to access images in the specified path and setting size 150 using target_size variable\n",
        "3. Using img_to_array to convert images to array\n",
        "4. Standardizing images by dividing them with 255 for easy computation\n",
        "5. Appending all the scaled images into an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmBU3R2CZsFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(path,y):\n",
        "    array=[]\n",
        "    img_cat = []\n",
        "    for img_path in tqdm(path):\n",
        "        img = load_img(img_path, target_size=(150,150))\n",
        "        img = img_to_array(img)\n",
        "        img = img/255.\n",
        "        array.append(img)\n",
        "        img_cat.append(y)\n",
        "    return np.array(array), np.array(img_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRIwMxN9d-1t",
        "colab_type": "text"
      },
      "source": [
        "**Accessing all trained images according to their categories**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GXhG4YfPM9D",
        "colab_type": "text"
      },
      "source": [
        "1. Using glob to retrieve files in the specific path\n",
        "2. Storing images of each categories in their specific names\n",
        "3. Setting values starting from 0 to each categories available using convert function\n",
        "4. Storing the converted images into trainX, trainY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y5kWJLYaDRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61c9cb43-919f-498c-81ae-636825db3ce9"
      },
      "source": [
        "buildings = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_train/buildings/*')\n",
        "trainX_building, trainY_building  = convert(buildings,0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2191/2191 [21:39<00:00,  1.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugUPyCYvanTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "309d4979-af07-41e9-d882-8e3f78fe5eec"
      },
      "source": [
        "print('train building shape ', trainX_building.shape, trainY_building.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train building shape  (2191, 150, 150, 3) (2191,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_s--JO9bc6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d286f5f-0f8a-4efb-eb30-a86201f45fca"
      },
      "source": [
        "forest = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_train/forest/*')\n",
        "trainX_forest,trainY_forest  = convert(forest,1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2271/2271 [22:30<00:00,  1.68it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTWRb3fVln78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5fef03b-cef0-4b7a-933d-590c4b1ee8d4"
      },
      "source": [
        "glacier = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_train/glacier/*')\n",
        "trainX_glacier,trainY_glacier  = convert(glacier,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2404/2404 [22:08<00:00,  1.81it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtevlRRKl5Sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b39257e-3768-46e3-90f7-bf22eac9de66"
      },
      "source": [
        "mount = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_train/mountain/*')\n",
        "trainX_mount,trainY_mount  = convert(mount,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2512/2512 [23:42<00:00,  1.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN6Vrxo-mGup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70ae0ec1-cc3f-4c73-e343-1fd4a8074582"
      },
      "source": [
        "sea = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_train/sea/*')\n",
        "trainX_sea,trainY_sea  = convert(sea,4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2274/2274 [22:15<00:00,  1.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMgCBvFwmTyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41fa287f-b80d-41a8-d4d9-8dcdfe27907d"
      },
      "source": [
        "street = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_train/street/*')\n",
        "trainX_street,trainY_street  = convert(street,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2382/2382 [22:41<00:00,  1.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OHkuEJ5P61P",
        "colab_type": "text"
      },
      "source": [
        "**Checking the shape of data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePkKXSDeldmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cf18508f-ed37-414e-f48c-7c680d24ecb2"
      },
      "source": [
        "print('train building shape ', trainX_building.shape, trainY_building.shape) \n",
        "print('train forest', trainX_forest.shape ,trainY_forest.shape)\n",
        "print('train glacier', trainX_glacier.shape,trainY_glacier.shape)\n",
        "print('train mountain', trainX_mount.shape, trainY_mount.shape)\n",
        "print('train sea',     trainX_sea.shape, trainY_sea.shape)\n",
        "print('train street', trainX_street.shape ,trainY_street.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train building shape  (2191, 150, 150, 3) (2191,)\n",
            "train forest (2271, 150, 150, 3) (2271,)\n",
            "train glacier (2404, 150, 150, 3) (2404,)\n",
            "train mountain (2512, 150, 150, 3) (2512,)\n",
            "train sea (2274, 150, 150, 3) (2274,)\n",
            "train street (2382, 150, 150, 3) (2382,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFtv47b7QC03",
        "colab_type": "text"
      },
      "source": [
        "**Concatenating all train categories**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guBpAM4wQKXN",
        "colab_type": "text"
      },
      "source": [
        "1. Using concatenate function we are combining the trainX data of all categorical images into X_train\n",
        "2. Combining trainY data of all images into Y_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcwVC6KVmiHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train= np.concatenate((trainX_building,trainX_forest, trainX_glacier,trainX_mount, trainX_sea,trainX_street),axis=0)\n",
        "y_train= np.concatenate((trainY_building,trainY_forest, trainY_glacier,trainY_mount, trainY_sea,trainY_street),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgiudnPumhn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33444669-fb2f-4030-cba5-f4031765dabe"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14034, 150, 150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnv966_rmhfx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bd892e9-912e-46d1-f913-62bcea6a2c6a"
      },
      "source": [
        "X_train.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btYDaOUnaPTn",
        "colab_type": "text"
      },
      "source": [
        "**Saving the data into drive in npy format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrGF9plQmhVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import save\n",
        "\n",
        "save('X_train.npy', X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_fOcQojC_vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp X_train.npy \"/content/drive/My Drive/data/Intel_Image_Classification/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK45RQeaB7Ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load\n",
        "\n",
        "X_train = load('/content/drive/My Drive/data/Intel_Image_Classification/X_train1.npy.npz')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vDqLjS7sSk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train['arr_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4byE0LzQCjn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d67ef2f0-0237-4027-9210-5e22845ba6c6"
      },
      "source": [
        "X_train.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htfGybyAsepz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dad2c66-1b46-4726-e12f-a0afe392eea5"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14034, 150, 150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wey-9s0EjrWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load\n",
        "\n",
        "y_train = load('/content/drive/My Drive/data/Intel_Image_Classification/y_train.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oanGQse-F0Mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85846448-7a6a-4115-ee18-e4422f44284c"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14034,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWJNmq7sF0FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvTA3MIRs3Ny",
        "colab_type": "text"
      },
      "source": [
        "**Converting test data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sk6u4vlQrEp",
        "colab_type": "text"
      },
      "source": [
        "1. Using the similar steps as performed for train data\n",
        "2. Accessing test data of each categories using glob function\n",
        "3. Storing them in their respective variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iETD9IUNQmi3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwm6Gok1F0DX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "822b6448-1b33-44f0-8392-ffa70d8fa44e"
      },
      "source": [
        "buildings_test = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_test/buildings/*')\n",
        "testX_building, testY_building  = convert(buildings_test,0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 437/437 [04:59<00:00,  1.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmx7QRQgtTQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forest_test = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_test/forest/*')\n",
        "testX_forest, testY_forest  = convert(forest_test,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVClg4UatKmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glacier_test = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_test/glacier/*')\n",
        "testX_glacier, testY_glacier  = convert(glacier_test,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPiNbUkjujyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mountain_test = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_test/mountain/*')\n",
        "testX_mountain, testY_mountain  = convert(mountain_test,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i70vE_XkuyIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sea_test = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_test/sea/*')\n",
        "testX_sea, testY_sea  = convert(sea_test,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6CxJXmEvGJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "street_test = glob.glob('/content/drive/My Drive/data/Intel_Image_Classification/seg_test/street/*')\n",
        "testX_street, testY_street  = convert(street_test,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoGTuzsuQ6V3",
        "colab_type": "text"
      },
      "source": [
        "**Concatenating all Test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nVVMHq6vGIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test= np.concatenate((testX_building,testX_forest, testX_glacier,testX_mountain, testX_sea,testX_street),axis=0)\n",
        "y_test= np.concatenate((testY_building,testY_forest, testY_glacier,testY_mountain, testY_sea,testY_street),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3MItX0Wambo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import save\n",
        "\n",
        "save('X_test.npy', X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOoy7yWGarKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp X_test.npy \"/content/drive/My Drive/data/Intel_Image_Classification/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBPNIkmIarCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import save\n",
        "\n",
        "save('y_test.npy', y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p1yJo9Gaq1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp y_test.npy \"/content/drive/My Drive/data/Intel_Image_Classification/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wtFhOfJwZYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9129c093-fd95-4246-c242-f9163186a04b"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14034, 150, 150, 3), (3000, 150, 150, 3), (14034,), (3000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyfNqBUURP12",
        "colab_type": "text"
      },
      "source": [
        "**Converting label data to one-hot vector** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXbhONoyRXnn",
        "colab_type": "text"
      },
      "source": [
        "1. We use to_categorical to convert our array into one-hot encoded vectors\n",
        "2. We encode both y_train and y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eea46BItyzQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf70729f-5056-4f9f-98fc-b48a043a2820"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_train.shape,y_test.shape\n",
        "y_test[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzOo-anmJwXS",
        "colab_type": "text"
      },
      "source": [
        "**RESNET50** **with inbuilt pretrained weights by the imagenet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDvJTAkuyy56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71MI4PBTR0Vg",
        "colab_type": "text"
      },
      "source": [
        "1. Applying the state-of-the-art algorithm ResNet50 for our data by simply specifying ResNet50 for the input data\n",
        "2. We take pretrained weights from the imagenet\n",
        "3. We use include_top= False to modify output according to our requirement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKezqiURvF5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = ResNet50(input_shape= (150, 150, 3), weights='imagenet', include_top=False )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjKDpay4SRXR",
        "colab_type": "text"
      },
      "source": [
        "1. We use layer.trainable=False to avoid training of the whole dataset since they are already trained\n",
        "2. We directly use the model without training it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CnvRH3BzCWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2261L1h_zCIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeiKTASkShhh",
        "colab_type": "text"
      },
      "source": [
        "1. Since the softmax is applied on 1D , we Flatten the data that is obtained from above layers using Flatten function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTanth9ezB3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Flatten()(resnet.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERZNQyvLSxm2",
        "colab_type": "text"
      },
      "source": [
        "1. Dense function is used to get a fully connected layer\n",
        "2. Activation is applied as Softmax as value is given as 6, indicating the number of categories our data belong to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7TjH7y9zddx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = Dense(6, activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=resnet.input, outputs=prediction)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHCI97hLzdYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e26aae49-4ce2-46ea-989b-f6b1bc4c7e6f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 75, 75, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 75, 75, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 38, 38, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 38, 38, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 38, 38, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 38, 38, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 38, 38, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 38, 38, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 38, 38, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 38, 38, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 38, 38, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 38, 38, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 38, 38, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 38, 38, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 38, 38, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 38, 38, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 38, 38, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 38, 38, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 19, 19, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 19, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 19, 19, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 19, 19, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 19, 19, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 19, 19, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 19, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 19, 19, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 19, 19, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 19, 19, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 19, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 19, 19, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 19, 19, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 19, 19, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 19, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 19, 19, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 19, 19, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 19, 19, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 10, 10, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 10, 10, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 10, 10, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 10, 10, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 10, 10, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 10, 10, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 10, 10, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 10, 10, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 10, 10, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 10, 10, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 10, 10, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 10, 10, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 10, 10, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 10, 10, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 10, 10, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 10, 10, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 10, 10, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 10, 10, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 10, 10, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 10, 10, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 10, 10, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 10, 10, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 10, 10, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 10, 10, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 10, 10, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 10, 10, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 5, 5, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 5, 5, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 5, 5, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 5, 5, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 5, 5, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 5, 5, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 5, 5, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 5, 5, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 5, 5, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 5, 5, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 5, 5, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 5, 5, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 5, 5, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 5, 5, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 5, 5, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 5, 5, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 51200)        0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            307206      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,894,918\n",
            "Trainable params: 307,206\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbD5P9jaTDv6",
        "colab_type": "text"
      },
      "source": [
        "1. Categorical crossentropy is used as loss function since it is single label catgorization i.e., each image belongs to only one category\n",
        "2. Adam optimizer is used for better optimization\n",
        "3. We are using accuracy as a metric for evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5x1IOOtzdXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmDJADQzTpC6",
        "colab_type": "text"
      },
      "source": [
        "**Fitting data to our model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHKKmpFjTxhh",
        "colab_type": "text"
      },
      "source": [
        "1. We use fit function to fit our training and test data for our ResNet model\n",
        "2. We specify number of epochs as 50 for better stability in accuracy\n",
        "3. Validation data is given as our test data\n",
        "4. Batch size can be of any size ie., 32 or 64 depending upon our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6uU-_0bzdK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46699325-9a7b-4f04-9ae8-201aa307a8ad"
      },
      "source": [
        "r = model.fit(X_train, y_train, epochs = 50, batch_size = 64,validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "220/220 [==============================] - 61s 276ms/step - loss: 1.2562 - accuracy: 0.5219 - val_loss: 1.0763 - val_accuracy: 0.5677\n",
            "Epoch 2/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.9449 - accuracy: 0.6312 - val_loss: 1.0897 - val_accuracy: 0.5737\n",
            "Epoch 3/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.8860 - accuracy: 0.6514 - val_loss: 0.8790 - val_accuracy: 0.6587\n",
            "Epoch 4/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.7925 - accuracy: 0.7001 - val_loss: 0.8747 - val_accuracy: 0.6780\n",
            "Epoch 5/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.8010 - accuracy: 0.6895 - val_loss: 0.8351 - val_accuracy: 0.6637\n",
            "Epoch 6/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.7432 - accuracy: 0.7141 - val_loss: 0.8328 - val_accuracy: 0.6710\n",
            "Epoch 7/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.7262 - accuracy: 0.7197 - val_loss: 0.8102 - val_accuracy: 0.6910\n",
            "Epoch 8/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.7144 - accuracy: 0.7263 - val_loss: 0.7854 - val_accuracy: 0.7163\n",
            "Epoch 9/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6871 - accuracy: 0.7383 - val_loss: 0.9212 - val_accuracy: 0.6543\n",
            "Epoch 10/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6930 - accuracy: 0.7359 - val_loss: 0.7515 - val_accuracy: 0.7200\n",
            "Epoch 11/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6691 - accuracy: 0.7469 - val_loss: 0.8039 - val_accuracy: 0.6970\n",
            "Epoch 12/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6615 - accuracy: 0.7474 - val_loss: 0.8111 - val_accuracy: 0.6860\n",
            "Epoch 13/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6259 - accuracy: 0.7623 - val_loss: 0.7850 - val_accuracy: 0.7133\n",
            "Epoch 14/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6607 - accuracy: 0.7451 - val_loss: 0.7618 - val_accuracy: 0.7200\n",
            "Epoch 15/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6116 - accuracy: 0.7679 - val_loss: 0.7869 - val_accuracy: 0.7107\n",
            "Epoch 16/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6315 - accuracy: 0.7575 - val_loss: 0.7567 - val_accuracy: 0.7163\n",
            "Epoch 17/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.6010 - accuracy: 0.7743 - val_loss: 0.8737 - val_accuracy: 0.6630\n",
            "Epoch 18/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5948 - accuracy: 0.7764 - val_loss: 0.8055 - val_accuracy: 0.7050\n",
            "Epoch 19/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5972 - accuracy: 0.7711 - val_loss: 0.8337 - val_accuracy: 0.7093\n",
            "Epoch 20/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5902 - accuracy: 0.7768 - val_loss: 0.7749 - val_accuracy: 0.7143\n",
            "Epoch 21/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5729 - accuracy: 0.7865 - val_loss: 0.8285 - val_accuracy: 0.6923\n",
            "Epoch 22/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5763 - accuracy: 0.7826 - val_loss: 0.7878 - val_accuracy: 0.7190\n",
            "Epoch 23/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5703 - accuracy: 0.7840 - val_loss: 0.8345 - val_accuracy: 0.6917\n",
            "Epoch 24/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5573 - accuracy: 0.7945 - val_loss: 0.8386 - val_accuracy: 0.6840\n",
            "Epoch 25/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5518 - accuracy: 0.7948 - val_loss: 0.8274 - val_accuracy: 0.7110\n",
            "Epoch 26/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5683 - accuracy: 0.7875 - val_loss: 0.7790 - val_accuracy: 0.7177\n",
            "Epoch 27/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5555 - accuracy: 0.7943 - val_loss: 0.7776 - val_accuracy: 0.7203\n",
            "Epoch 28/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5445 - accuracy: 0.7980 - val_loss: 0.7674 - val_accuracy: 0.7320\n",
            "Epoch 29/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5271 - accuracy: 0.8057 - val_loss: 0.8012 - val_accuracy: 0.7217\n",
            "Epoch 30/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5437 - accuracy: 0.7947 - val_loss: 0.7777 - val_accuracy: 0.7370\n",
            "Epoch 31/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5202 - accuracy: 0.8083 - val_loss: 0.7486 - val_accuracy: 0.7400\n",
            "Epoch 32/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5265 - accuracy: 0.8039 - val_loss: 0.7449 - val_accuracy: 0.7510\n",
            "Epoch 33/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5030 - accuracy: 0.8158 - val_loss: 0.7458 - val_accuracy: 0.7453\n",
            "Epoch 34/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5271 - accuracy: 0.8048 - val_loss: 0.9450 - val_accuracy: 0.6650\n",
            "Epoch 35/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5446 - accuracy: 0.7961 - val_loss: 0.7503 - val_accuracy: 0.7417\n",
            "Epoch 36/50\n",
            "220/220 [==============================] - 58s 265ms/step - loss: 0.5298 - accuracy: 0.8052 - val_loss: 0.7722 - val_accuracy: 0.7363\n",
            "Epoch 37/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5016 - accuracy: 0.8137 - val_loss: 0.8339 - val_accuracy: 0.7173\n",
            "Epoch 38/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5205 - accuracy: 0.8043 - val_loss: 0.7956 - val_accuracy: 0.7320\n",
            "Epoch 39/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.5040 - accuracy: 0.8153 - val_loss: 0.7903 - val_accuracy: 0.7260\n",
            "Epoch 40/50\n",
            "220/220 [==============================] - 58s 263ms/step - loss: 0.5042 - accuracy: 0.8125 - val_loss: 0.9520 - val_accuracy: 0.6710\n",
            "Epoch 41/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.4911 - accuracy: 0.8197 - val_loss: 0.7945 - val_accuracy: 0.7177\n",
            "Epoch 42/50\n",
            "220/220 [==============================] - 58s 263ms/step - loss: 0.4826 - accuracy: 0.8214 - val_loss: 0.8855 - val_accuracy: 0.6963\n",
            "Epoch 43/50\n",
            "220/220 [==============================] - 58s 263ms/step - loss: 0.4752 - accuracy: 0.8244 - val_loss: 0.9202 - val_accuracy: 0.6850\n",
            "Epoch 44/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.4866 - accuracy: 0.8242 - val_loss: 0.9011 - val_accuracy: 0.6823\n",
            "Epoch 45/50\n",
            "220/220 [==============================] - 58s 263ms/step - loss: 0.4996 - accuracy: 0.8149 - val_loss: 0.7724 - val_accuracy: 0.7320\n",
            "Epoch 46/50\n",
            "220/220 [==============================] - 58s 264ms/step - loss: 0.4613 - accuracy: 0.8301 - val_loss: 0.8065 - val_accuracy: 0.7233\n",
            "Epoch 47/50\n",
            "220/220 [==============================] - 58s 263ms/step - loss: 0.4634 - accuracy: 0.8308 - val_loss: 0.7716 - val_accuracy: 0.7467\n",
            "Epoch 48/50\n",
            "220/220 [==============================] - 58s 263ms/step - loss: 0.4572 - accuracy: 0.8338 - val_loss: 0.7933 - val_accuracy: 0.7353\n",
            "Epoch 49/50\n",
            "220/220 [==============================] - 58s 263ms/step - loss: 0.4757 - accuracy: 0.8220 - val_loss: 0.7704 - val_accuracy: 0.7493\n",
            "Epoch 50/50\n",
            "220/220 [==============================] - 58s 263ms/step - loss: 0.4499 - accuracy: 0.8356 - val_loss: 0.7761 - val_accuracy: 0.7363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZYRkc1zUReA",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating performance of our model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJRmcls6UY_Z",
        "colab_type": "text"
      },
      "source": [
        "1. We use evaluate function to test accuracy of our test data on our trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlhtNq2H6GSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "89d5a271-db4e-4006-b669-e38744d0e870"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 11s 122ms/step - loss: 0.7761 - accuracy: 0.7363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.776053249835968, 0.7363333106040955]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckYGlP-hUjN6",
        "colab_type": "text"
      },
      "source": [
        "**OBSERVATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XBTc6imUtEd",
        "colab_type": "text"
      },
      "source": [
        "1. We got an accuracy of 73.63 using ResNet50 as our model\n",
        "2. We obtained loss of 0.7761 which shows moderate performance of ResNet50 on our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjoPdjgJHo5Q",
        "colab_type": "text"
      },
      "source": [
        "**VGG16** **with inbuilt pretrained images by imagenet**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoMBkicJHnK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "199a082a-ee00-4317-d524-1fded6abeca3"
      },
      "source": [
        "from keras.applications import VGG16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoFS9IqDN-s_",
        "colab_type": "text"
      },
      "source": [
        "1. Using VGG16 model for our data\n",
        "2. Using pretrained weights of images by imagenet\n",
        "3. Specifying include_top=False to modify output layer according to our requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aYHO-rNHnJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c269ea10-c547-47d9-c956-b16a6e37d5b1"
      },
      "source": [
        "vgg_conv = VGG16(weights='imagenet',\n",
        "                  include_top=False,input_shape=(150,150,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNLvVjOtHnFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "b1b74a56-a9e0-45b1-e967-7738a8f50041"
      },
      "source": [
        "vgg_conv.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0iOzXVSVYpL",
        "colab_type": "text"
      },
      "source": [
        "1. Models.Sequential is used to define the beginning of our model\n",
        "2. We add vgg_conv which has our predeined VGG16 layers\n",
        "3. We flatten the data before using softmax since it accepts 1D as input\n",
        "4. We use dropout to avoid overfitting of data \n",
        "5. Activation function is used as softmax as value is specified as 6 , since we have 6 categorical images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHHw0X9cHnEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models as Models\n",
        "from keras import layers as Layers\n",
        "model1=Models.Sequential()\n",
        "model1.add(vgg_conv)\n",
        "model1.add(Layers.Flatten())\n",
        "model1.add(Layers.Dense(180,activation='relu'))\n",
        "model1.add(Layers.Dense(100,activation='relu'))\n",
        "model1.add(Layers.Dense(50,activation='relu'))\n",
        "model1.add(Layers.Dropout(rate=0.5))\n",
        "model1.add(Layers.Dense(6,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-udj7PoHmy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a93e9c8a-7771-43cd-a147-0977d0ec6f52"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 180)               1474740   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               18100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 16,212,884\n",
            "Trainable params: 16,212,884\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsXMZYm0V8Wu",
        "colab_type": "text"
      },
      "source": [
        "Similar to ResNet50, we donot train the VGG16 layers since it is already trained thus we use .trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui93HrXTHmwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_conv.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRoGAnLpIvHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a53f4e9b-34f7-4062-966d-cd6c30eea7fd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 75, 75, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 75, 75, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 38, 38, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 38, 38, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 38, 38, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 38, 38, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 38, 38, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 38, 38, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 38, 38, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 38, 38, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 38, 38, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 38, 38, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 38, 38, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 38, 38, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 38, 38, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 38, 38, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 38, 38, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 38, 38, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 38, 38, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 38, 38, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 19, 19, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 19, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 19, 19, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 19, 19, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 19, 19, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 19, 19, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 19, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 19, 19, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 19, 19, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 19, 19, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 19, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 19, 19, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 19, 19, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 19, 19, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 19, 19, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 19, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 19, 19, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 19, 19, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 19, 19, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 19, 19, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 10, 10, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 10, 10, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 10, 10, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 10, 10, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 10, 10, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 10, 10, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 10, 10, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 10, 10, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 10, 10, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 10, 10, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 10, 10, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 10, 10, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 10, 10, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 10, 10, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 10, 10, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 10, 10, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 10, 10, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 10, 10, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 10, 10, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 10, 10, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 10, 10, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 10, 10, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 10, 10, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 10, 10, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 10, 10, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 10, 10, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 10, 10, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 10, 10, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 10, 10, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 5, 5, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 5, 5, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 5, 5, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 5, 5, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 5, 5, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 5, 5, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 5, 5, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 5, 5, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 5, 5, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 5, 5, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 5, 5, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 5, 5, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 5, 5, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 5, 5, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 5, 5, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 5, 5, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 51200)        0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            307206      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,894,918\n",
            "Trainable params: 307,206\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79RjbJE8WN7s",
        "colab_type": "text"
      },
      "source": [
        "1. Using Catrgorical cross entropy as loss since data is single value category\n",
        "2. We use Adam optimizer as it yields better optimization results\n",
        "3. Metrics used to evaluate the performance of model is Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDVpn-49IvDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-7nDwLcWh7q",
        "colab_type": "text"
      },
      "source": [
        "**Fitting Train data to our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANuhekVDIvBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f26628e4-2618-4d3b-db26-2327b25718cf"
      },
      "source": [
        "vgg_model = model1.fit(X_train, y_train, epochs = 50, batch_size = 64,validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14034 samples, validate on 3000 samples\n",
            "Epoch 1/50\n",
            "14034/14034 [==============================] - 82s 6ms/step - loss: 0.6791 - accuracy: 0.7575 - val_loss: 0.3614 - val_accuracy: 0.8690\n",
            "Epoch 2/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.4065 - accuracy: 0.8653 - val_loss: 0.3673 - val_accuracy: 0.8623\n",
            "Epoch 3/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.3289 - accuracy: 0.8897 - val_loss: 0.3698 - val_accuracy: 0.8677\n",
            "Epoch 4/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.2926 - accuracy: 0.9012 - val_loss: 0.3342 - val_accuracy: 0.8850\n",
            "Epoch 5/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.2453 - accuracy: 0.9169 - val_loss: 0.3928 - val_accuracy: 0.8770\n",
            "Epoch 6/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.2152 - accuracy: 0.9272 - val_loss: 0.3795 - val_accuracy: 0.8810\n",
            "Epoch 7/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.1757 - accuracy: 0.9411 - val_loss: 0.4405 - val_accuracy: 0.8850\n",
            "Epoch 8/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.1582 - accuracy: 0.9453 - val_loss: 0.4348 - val_accuracy: 0.8777\n",
            "Epoch 9/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.1412 - accuracy: 0.9519 - val_loss: 0.4263 - val_accuracy: 0.8807\n",
            "Epoch 10/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.1364 - accuracy: 0.9519 - val_loss: 0.5078 - val_accuracy: 0.8767\n",
            "Epoch 11/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.1129 - accuracy: 0.9634 - val_loss: 0.5313 - val_accuracy: 0.8823\n",
            "Epoch 12/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0908 - accuracy: 0.9683 - val_loss: 0.6033 - val_accuracy: 0.8777\n",
            "Epoch 13/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0802 - accuracy: 0.9738 - val_loss: 0.6639 - val_accuracy: 0.8833\n",
            "Epoch 14/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0897 - accuracy: 0.9706 - val_loss: 0.5600 - val_accuracy: 0.8740\n",
            "Epoch 15/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0938 - accuracy: 0.9701 - val_loss: 0.6265 - val_accuracy: 0.8750\n",
            "Epoch 16/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.7051 - val_accuracy: 0.8687\n",
            "Epoch 17/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.6840 - val_accuracy: 0.8717\n",
            "Epoch 18/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0493 - accuracy: 0.9847 - val_loss: 0.7192 - val_accuracy: 0.8707\n",
            "Epoch 19/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0558 - accuracy: 0.9826 - val_loss: 0.8456 - val_accuracy: 0.8720\n",
            "Epoch 20/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0388 - accuracy: 0.9882 - val_loss: 0.8595 - val_accuracy: 0.8680\n",
            "Epoch 21/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0423 - accuracy: 0.9867 - val_loss: 0.8386 - val_accuracy: 0.8723\n",
            "Epoch 22/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0431 - accuracy: 0.9853 - val_loss: 0.7597 - val_accuracy: 0.8807\n",
            "Epoch 23/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0425 - accuracy: 0.9866 - val_loss: 1.0015 - val_accuracy: 0.8740\n",
            "Epoch 24/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0671 - accuracy: 0.9795 - val_loss: 0.8302 - val_accuracy: 0.8767\n",
            "Epoch 25/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0477 - accuracy: 0.9845 - val_loss: 0.7549 - val_accuracy: 0.8730\n",
            "Epoch 26/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.8288 - val_accuracy: 0.8850\n",
            "Epoch 27/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 1.0010 - val_accuracy: 0.8713\n",
            "Epoch 28/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.8296 - val_accuracy: 0.8693\n",
            "Epoch 29/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.9942 - val_accuracy: 0.8793\n",
            "Epoch 30/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.9775 - val_accuracy: 0.8820\n",
            "Epoch 31/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.9278 - val_accuracy: 0.8727\n",
            "Epoch 32/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0334 - accuracy: 0.9909 - val_loss: 0.9983 - val_accuracy: 0.8563\n",
            "Epoch 33/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0550 - accuracy: 0.9835 - val_loss: 0.8431 - val_accuracy: 0.8723\n",
            "Epoch 34/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.9920 - val_accuracy: 0.8803\n",
            "Epoch 35/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 1.0448 - val_accuracy: 0.8607\n",
            "Epoch 36/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.0967 - val_accuracy: 0.8780\n",
            "Epoch 37/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 1.1068 - val_accuracy: 0.8780\n",
            "Epoch 38/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0361 - accuracy: 0.9893 - val_loss: 0.9380 - val_accuracy: 0.8857\n",
            "Epoch 39/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0269 - accuracy: 0.9927 - val_loss: 1.1473 - val_accuracy: 0.8567\n",
            "Epoch 40/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 1.0503 - val_accuracy: 0.8850\n",
            "Epoch 41/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 1.0931 - val_accuracy: 0.8710\n",
            "Epoch 42/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.9811 - val_accuracy: 0.8767\n",
            "Epoch 43/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.9450 - val_accuracy: 0.8770\n",
            "Epoch 44/50\n",
            "14034/14034 [==============================] - 75s 5ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 1.0409 - val_accuracy: 0.8613\n",
            "Epoch 45/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 1.0377 - val_accuracy: 0.8800\n",
            "Epoch 46/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 1.0708 - val_accuracy: 0.8743\n",
            "Epoch 47/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 1.2114 - val_accuracy: 0.8817\n",
            "Epoch 48/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 1.7379 - val_accuracy: 0.8180\n",
            "Epoch 49/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0440 - accuracy: 0.9854 - val_loss: 0.9979 - val_accuracy: 0.8737\n",
            "Epoch 50/50\n",
            "14034/14034 [==============================] - 76s 5ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.1112 - val_accuracy: 0.8843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbrONqPbXHO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifLl86kwKGVr",
        "colab_type": "text"
      },
      "source": [
        "**Graph For Model Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8d7CUJsKF3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "aa248c33-40be-4509-8e58-46ca48e2b8d7"
      },
      "source": [
        "plt.plot(vgg_model.history['accuracy'])\n",
        "plt.plot(vgg_model.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(vgg_model.history['loss'])\n",
        "plt.plot(vgg_model.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx3tj5yDYJXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68e7c8bb-58f8-4afc-d647-5908f4cfc380"
      },
      "source": [
        "model1.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000/3000 [==============================] - 18s 6ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1111877498591203, 0.8843333125114441]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVrKEFe8aESl",
        "colab_type": "text"
      },
      "source": [
        "Pretty Table "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7plmgbicbDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "x = PrettyTable()\n",
        "\n",
        "x.field_names = [\"Model\", \"Train Loss\", \"Test Loss\", \"Train Accuracy\", \"Test Accuracy\"]\n",
        "\n",
        "x.add_row([\"Resnet50\",0.449,0.776,83.5,73.6])\n",
        "x.add_row([\"VGG16\",0.008,1.111,99.6,88.4])\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZzxhwobedCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "46fd77bd-d38c-45e1-8979-30ed15cd5ead"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------------+-----------+----------------+---------------+\n",
            "|  Model   | Train Loss | Test Loss | Train Accuracy | Test Accuracy |\n",
            "+----------+------------+-----------+----------------+---------------+\n",
            "| Resnet50 |   0.449    |   0.776   |      83.5      |      73.6     |\n",
            "|  VGG16   |   0.008    |   1.111   |      99.6      |      88.4     |\n",
            "+----------+------------+-----------+----------------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEJ2SaHVe21G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}